<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://dynodave4.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dynodave4.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-02T15:27:19+00:00</updated><id>https://dynodave4.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">P1 - A Primer for Probability</title><link href="https://dynodave4.github.io/blog/2024/Probability1/" rel="alternate" type="text/html" title="P1 - A Primer for Probability"/><published>2024-07-27T00:00:00+00:00</published><updated>2024-07-27T00:00:00+00:00</updated><id>https://dynodave4.github.io/blog/2024/Probability1</id><content type="html" xml:base="https://dynodave4.github.io/blog/2024/Probability1/"><![CDATA[<p>In this post, I’ll introduce an important definition in Probability Theory, the concept of a probability measure. We’ll build up to this definition by considering different “experiments” and using our intuition to see what we expect to happen.</p> <p>For our first experiment, let’s toss a fair coin and record the result. There are only possibilities; heads and tails. By a “fair” coin we mean that we have an equal probability of getting H or T, namely 50%. Using the logical operators of “not” and “or” we can observe some other probabilities. There is a 100% chance we get a heads or a tails and 100% = 50% + 50% = P(Heads) + P(Tails). There is a 0% chance of getting neither heads nor tails. There is a 50% chance of not getting heads, i.e. getting tails, and notice that this is 100% - P(Heads). Of course, we can run more complicated “experiments” with more than two possible outcomes. While it is tempting to try to describe the probabilities of observing each particular output value (e.g. H or T), the “atoms” of our experiment, for an infinite range of outputs, it will be more useful to describe the probability of being in a certain region instead. Then, using the logical operations of “not” and “or,” we will extend the possible probabilities we can observe. This will make more sense in the next discussion.</p> <p>For our second experiment, let’s pretend we are picking a real number in the unit interval [0, 1], or if you like spinning a wheel labeled between 0 and 1, and landing on some number in this interval. Let’s also assume that for any subinterval [a, b] there is a probability of b-a of landing in this subinterval. This means there is a 1-0 = 100% chance of being in the interval [0, 1] and there is a 1/3 = 2/3 - 1/3 chance of being in the interval [1/3, 2/3]. Let’s try figure out what “not” and “or” might do here. There should be a 100% chance of getting some number, so if you are not in [a,b] there is a probability of 1 - (b-a) of not being in [a,b]. If we have two intervals [a,b] and [c,d] it may not be the case that we can just add the probabilities. Notice, landing in [0, .2] or [.1, .3] is the same as landing in the interval [0, .3] which has probability 0.3 not 0.2 + 0.2 = 0.4. This concept is called “double counting” in combinatorics and so we should be careful not to add up probabilities when the intervals overlap. Whenever the intervals do not overlap, we should expect the probabilities to just add up. In fact, it would be nice if we can do this for countably many disjoint sets so long as the sum converges. Let’s see why we shouldn’t expect this to work for uncountable sums.</p> <p>Pick any point \(p\) in the interval (0, 1). If our experiment returns the value of \(p\), then we did not land in the interval [0, p/2] or [(p+1)/2, 1] which had a probability 1 - (p+1)/2 + p/2 - 0 = 1/2 chance of occuring. In fact, for any natural number n, we did not land in the intervals [0, (n-1)p/n] or [((n-1)p+1)/n, 1] which had probability 1 - ((n-1)p+1)/n + (n-1)p/n - 0 = 1 - 1/n chance of occuring. As we let n get really, big, we see that there is a 100% chance of not landing on this point, and a similar proof works for the endpoints as well. There are uncountable many points in [0, 1], and even though most people haven’t seen how to add uncountable many things, adding zero to itself, no matter how many times, should return 0. Even though the collection of points in [0, 1] are disjoint subsets, adding up the uncountably many zeros gives a probability of 0% of landing anywhere in [0, 1] which is a contradiction.</p> <p>So, what is a probability measure? Pretend we are running an experiment with possible output values in some set \(\Omega\). Then a probability measure is a function (\(\mu\) or \(\mathbb{P}\)) that takes in certain subsets \(B\) of \(\Omega\) and returns the probability of the experiment landing in \(B\), necessarily a nonnegative number. This function should always return that there is a 100% chance of landing in \(\Omega\) (\(\mathbb{P}(\Omega) = 1\)), and a 0% chance of returning outside of \(\Omega\). If we have countably many disjoint subsets \(B_n \subset \Omega\), then the probability of observing the experiment in any one of these sets is the sum of the probabilities.</p> <p>Here are some more quick facts to think about:</p> <ol> <li>Often times we construct a probability measure by defining probabilities on certain “nice” sets and then building up more complicated sets using “not” and “or” (or union, intersection, and complement). We could consider experiments occurring in the unit cube, define the probability of landing in a sub-rectangular prism as its volume, and then build up from these sets.</li> <li>Usually we can not define the probability for every subset of \(\Omega\). For instance, let’s consider a subset \(B\) of [0, 1] where for every point \(p \in [0, 1]\) there is exactly one point \(q \in B\) such that \(p-q\) is a rational number. Then this subset does not have a defined probability so it is “not measurable”.</li> <li>Even for nonmeasurable sets \(B\), we might be able to “approximate” a measure for \(B\) by taking the minimum/ maximum of measurable sets \(\mu (C)\) for measurable sets \(C\) where \(B \subset C\) / \(C \subset B\).</li> <li>We can build up “atoms” of positive probability in more interesting experiments. One such case for \(\Omega = [0, 1]\) would be that there is a 50% chance of observing 0, and probability (b-a)/2 of landing in [a,b] if \(a \neq 0\).</li> <li>In the next blog post, we’ll consider how for functions \(f : \Omega \rightarrow \Lambda\), we might be able to compare the probabilities in \(\Omega\) to the probabilities in \(f(\Omega) \subset \Lambda\).</li> </ol> <p>Exercises:</p> <ol> <li>For any measurable set \(B \subset \Omega\) and probability measure \(\mathbb{P}\), show that \(\mathbb{P}(B^c) = 1 - \mathbb{P}(B)\) so that the probability of landing outside of \(B\) is 1- probability of landing in B.</li> <li>For any measurable sets \(A, B \subset \Omega\) such that \(A \subset B\), show that \(\mathbb{P}(A) \leq \mathbb{P}(B)\).</li> </ol>]]></content><author><name></name></author><category term="Probability"/><summary type="html"><![CDATA[Probability Measures]]></summary></entry></feed>