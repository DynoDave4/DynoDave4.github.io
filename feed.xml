<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://dynodave4.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dynodave4.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-02T17:17:38+00:00</updated><id>https://dynodave4.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Probability2</title><link href="https://dynodave4.github.io/blog/2024/Probability2/" rel="alternate" type="text/html" title="Probability2"/><published>2024-08-02T00:00:00+00:00</published><updated>2024-08-02T00:00:00+00:00</updated><id>https://dynodave4.github.io/blog/2024/Probability2</id><content type="html" xml:base="https://dynodave4.github.io/blog/2024/Probability2/"><![CDATA[<p>__— layout: post title: P2 - Measure Preserving Transformations date: 2024-07-27 description: Probability Measures tags: categories: Probability related_posts: false —</p> <p>In this post, I’ll give another example of a measure space and introduce an important topic concept in ergodic theory; measure preserving transformations.</p> <p>One interesting space we often consider is the space of infinite sequences of numbers taken from some finite set which models rolling a die an infinite number of times. For instance, we could take our “alphabet” to be the set \(S = \{0, \, 1, \, \cdots \, n-1 \}\) consisting of \(n\) “letters”. Words taken from this alphabet could look something like \((0, \, 1, \, 0, \, 0, \, 0, \, 1, \, \cdots )\) and the set of all such words \((a_i) \, {i \in \mathbb{N}}\) is denoted \(\Pi_{i=1}^\infty \{ 0, \, 1, \, \cdots \, n-1\} = \Omega\). To construct a probability measure on this set, we should find some collection of simple sets to define their probability, and then we’ll be able to find the measure of any unions, intersections, and complements of these sets. If our die is fair, we would expect that the probability of the Ith roll \(a_I\) to be a particular number \(\omega_I \in S\) is \(1/n\) and that previous die rolls do not affect future rolls (independence). Thus we define \(\mathbb{P}(\{ (a_i) \, {i \in \mathbb{N}} : a_I = \omega_I \}) = 1/n\) and \(\mathbb{P}(\{ (a_i) {i \in \mathbb{N}} : a_I = \omega_I \} \cap \{ (a_i) \, {i \in \mathbb{N}} : a_J = \omega_J \}) = \mathbb{P}(\{ (a_i) \, {i \in \mathbb{N}} : a_I = \omega_I \}) * \mathbb{P}(\{ (a_i) \, {i \in \mathbb{N}} : a_J = \omega_J \})\) for all rolls \(I, J \in \mathbb{N}\) and letters \(\omega_I, \omega_J \in \mathbb{N}\). Taking intersections of these sets, we see that the probability of first rolling a zero and then a one is \(\mathbb{P}(\{ (a_i) \, {i \in \mathbb{N}} : a_1 = 0, \, a_2 = 1 \}) = \mathbb{P}(\{ (a_i) \,{i \in \mathbb{N}} : a_1 = 0 \} \cap \{ (a_i) \, {i \in \mathbb{N}} : a_2 = 1 \}) = 1/n^2\) and the probability of rolling either a zero or one on the first roll is \(\mathbb{P}(\{ (a_i) \, {i \in \mathbb{N}} : a_1 = 0 \} \cup \{ (a_i) \,{i \in \mathbb{N}} : a_1 = 1 \}) = 2/n\).</p> <table> <tbody> <tr> <td>Although it does not look it, this space is very similar to a space we’ve seen before; the unit interval [0, 1]. To see this, pretend that every sequence in \(\Omega\) represents the base-n decimal expansion of a number. This means we have a function \(f : \Omega \rightarrow [0, 1]\) sending a sequence \((a_i)\) to the number \(f((a_i)) = \Sum_{i=1}^\infty \; a_i / n^i\). So if \(n=10\), the sequence \((2, \, 3, \, 4, \, 0, \, 0, \, 0, \, \cdots)\) is sent to \(0.234\). It is clear that \(f\) is onto, but it is not one-to-one. Notice that the sequence of a one and then all nines is sent to \(0.19999\cdots = 0.20000\cdots\). Fortunately, this is the only thing that can go wrong (exercise). If we throw out all the sequences that end with the digit \(n-1\) repeating to create a set \(\Tilde{\Omega}\), then the function $$\Tilde{f} = f</td> <td>{\Tilde{\Omega}} : \Tilde{\Omega} \rightarrow [0, 1)\(is a bijection. We are also lucky that the probability of landing on an eventual sequence of\)n-1\(was zero. To see this, notice that the collection of sequences that are eventually all\)n-1\(is a countable union of sets\) \bigcup_{k=1}^\infty { (a_i) : a_i = n-1\(for all\) i \geq k } \(. Each of these sets is measure zero (exercise) and so their countable union is also measure zero (exercise). This function\)\Tilde{f}$$ also has another important property: preserving measure.</td> </tr> </tbody> </table> <p>Another equivalent way of defining all the measureable sets on \(\Omega\) is to define the probability of guessing the first \(m\) rolls correctly, not just the Ith roll. We could have set \(\mathbb{P}( \{ (a_i)_{i \in \mathbb{N}} : a_1 = \omega_1, \, \cdots \, a_m = \omega_m \}) = 1/n^m\) and the unions/ intersections of these sets gives us exactly the same probabilities and sets as before. Under the map \(\Tilde{f}\), these sets are sent to decimal expansions that begin with \(0. \omega_1 \omega_2 \omega_3 \cdots\) which is just the set \([0.\omega_1 \omega_2 \cdots \omega_m, \; 0.\omega_1 \omega_2 \cdots \omega_m + n^{-m})\). This is an interval of length/ measure \(n^{-m}\) (endpoints do not matter because they have zero measure) and so both sets have the same probability measure. Intuitively this statement says that there is equal likelyhood of guessing the first \(m\) rolls of a die of \(n\) sides as guessing the first \(m\) digits in the base \(n\) decimal expansion of a number in \([0, 1)\). We can use properties of the inverse function to extend this to all measurable sets.</p> <p>For all functions \(g$:X\rightarrow Y$ and sets\)A, B \subset Y\(, we have the equalities\)g^{-1}(A \cap B) = g^{-1}(A) \cup g^{-1}(B), \; g^{-1}(A \cap B) = g^{-1}(A) \cup g^{-1}(B), \; g^{-1}(A^c) = g^{-1}(A)^c \(. With these relations, we can show that for all measurable sets of\)B \subset \Tilde{\Omega}\((built out of unions, intersections, and complements of these simple sets), we have that\)\mathbb{P}(B) = \mathbb{P}(\Tilde{f}(B))\(. This discussion used the fact that\)\Tilde{f}\(was a bijection, but for any function\)g :X \rightarrow Y\(, you can define a multifunction\)g^{-1} (y) = {x \in X : g(x) = y} \(and the previous equalities still hold for\)g^{-1}$$. With this in mind, we can finally define a measure-preserving transformation.</p> <p>The collection of a set \(X\), with probability measure \(\mathbb{P}\), and a function \(T : X \rightarrow X\) is called a measure preserving transformation if \(\mathbb{P}(A) = \mathbb{P}(T^{-1}(A))\) for all measureable sets \(A \subset X\).</p> <p>Remarks:</p> <ol> <li>We have previously seen that not all subsets of \(X\) are necessarily measurable. Thus we need to assume \(T^{-1}(A)\) is measurable for all measurable \(A\). This property means that \(T\) is called measurable.</li> <li>It is not necessary to have a probability measure, only a measure. This means we could measure lengths on \([0,2]\) instead of \([0, 1]]\) or even all of \(\mathbb{R}\).</li> <li>Measure-preserving transformations are sometimes called volume-preserving transformations.</li> </ol> <p>Examples/ exercises:</p> <ol> <li>On our space \(\Omega\), consider the left shift \(\sigma\) where \(\sigma(a_1, \, a_2, \, a_3, \cdots) = (a_2, \, a_3, \cdots)\). Then \(\sigma\) is a measure preserving transformation.</li> <li>On the space \([0,1)\), pick a real number \(\alpha\) and define \(T\) to shift by \(\alpha\) i.e. \(T(x) = x + \alpha - \lceil x + \alpha \rceil\). Then \(T\) is a measure-preserving transformation.</li> <li>On the space \([0,1)\), pick a positive integer \(n\) and define \(T\) to give the fractional part of \(nx\) i.e. \(T(x) = nx - \lceil nx \rceil\). Then \(T\) is called the expanding endomorphism and is a measure-preserving transformation. Notice that it is not true that \(\mathbb{P}(A) = \mathbb{P}(T^(A))\) and it is still measure-preserving because our definition uses the inverse function.</li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[__— layout: post title: P2 - Measure Preserving Transformations date: 2024-07-27 description: Probability Measures tags: categories: Probability related_posts: false —]]></summary></entry><entry><title type="html">P1 - A Primer for Probability</title><link href="https://dynodave4.github.io/blog/2024/Probability1/" rel="alternate" type="text/html" title="P1 - A Primer for Probability"/><published>2024-07-27T00:00:00+00:00</published><updated>2024-07-27T00:00:00+00:00</updated><id>https://dynodave4.github.io/blog/2024/Probability1</id><content type="html" xml:base="https://dynodave4.github.io/blog/2024/Probability1/"><![CDATA[<p>In this post, I’ll introduce an important definition in Probability Theory, the concept of a probability measure. We’ll build up to this definition by considering different “experiments” and using our intuition to see what we expect to happen.</p> <p>For our first experiment, let’s toss a fair coin and record the result. There are only possibilities; heads and tails. By a “fair” coin we mean that we have an equal probability of getting H or T, namely 50%. Using the logical operators of “not” and “or” we can observe some other probabilities. There is a 100% chance we get a heads or a tails and 100% = 50% + 50% = P(Heads) + P(Tails). There is a 0% chance of getting neither heads nor tails. There is a 50% chance of not getting heads, i.e. getting tails, and notice that this is 100% - P(Heads). Of course, we can run more complicated “experiments” with more than two possible outcomes. While it is tempting to try to describe the probabilities of observing each particular output value (e.g. H or T), the “atoms” of our experiment, for an infinite range of outputs, it will be more useful to describe the probability of being in a certain region instead. Then, using the logical operations of “not” and “or,” we will extend the possible probabilities we can observe. This will make more sense in the next discussion.</p> <p>For our second experiment, let’s pretend we are picking a real number in the unit interval [0, 1], or if you like spinning a wheel labeled between 0 and 1, and landing on some number in this interval. Let’s also assume that for any subinterval [a, b] there is a probability of b-a of landing in this subinterval. This means there is a 1-0 = 100% chance of being in the interval [0, 1] and there is a 1/3 = 2/3 - 1/3 chance of being in the interval [1/3, 2/3]. Let’s try figure out what “not” and “or” might do here. There should be a 100% chance of getting some number, so if you are not in [a,b] there is a probability of 1 - (b-a) of not being in [a,b]. If we have two intervals [a,b] and [c,d] it may not be the case that we can just add the probabilities. Notice, landing in [0, .2] or [.1, .3] is the same as landing in the interval [0, .3] which has probability 0.3 not 0.2 + 0.2 = 0.4. This concept is called “double counting” in combinatorics and so we should be careful not to add up probabilities when the intervals overlap. Whenever the intervals do not overlap, we should expect the probabilities to just add up. In fact, it would be nice if we can do this for countably many disjoint sets so long as the sum converges. Let’s see why we shouldn’t expect this to work for uncountable sums.</p> <p>Pick any point \(p\) in the interval (0, 1). If our experiment returns the value of \(p\), then we did not land in the interval [0, p/2] or [(p+1)/2, 1] which had a probability 1 - (p+1)/2 + p/2 - 0 = 1/2 chance of occuring. In fact, for any natural number n, we did not land in the intervals [0, (n-1)p/n] or [((n-1)p+1)/n, 1] which had probability 1 - ((n-1)p+1)/n + (n-1)p/n - 0 = 1 - 1/n chance of occuring. As we let n get really, big, we see that there is a 100% chance of not landing on this point, and a similar proof works for the endpoints as well. There are uncountable many points in [0, 1], and even though most people haven’t seen how to add uncountable many things, adding zero to itself, no matter how many times, should return 0. Even though the collection of points in [0, 1] are disjoint subsets, adding up the uncountably many zeros gives a probability of 0% of landing anywhere in [0, 1] which is a contradiction.</p> <p>So, what is a probability measure? Pretend we are running an experiment with possible output values in some set \(\Omega\). Then a probability measure is a function (\(\mu\) or \(\mathbb{P}\)) that takes in certain subsets \(B\) of \(\Omega\) and returns the probability of the experiment landing in \(B\), necessarily a nonnegative number. This function should always return that there is a 100% chance of landing in \(\Omega\) (\(\mathbb{P}(\Omega) = 1\)), and a 0% chance of returning outside of \(\Omega\). If we have countably many disjoint subsets \(B_n \subset \Omega\), then the probability of observing the experiment in any one of these sets is the sum of the probabilities.</p> <p>Here are some more quick facts to think about:</p> <ol> <li>Often times we construct a probability measure by defining probabilities on certain “nice” sets and then building up more complicated sets using “not” and “or” (or union, intersection, and complement). We could consider experiments occurring in the unit cube, define the probability of landing in a sub-rectangular prism as its volume, and then build up from these sets.</li> <li>Usually we can not define the probability for every subset of \(\Omega\). For instance, let’s consider a subset \(B\) of [0, 1] where for every point \(p \in [0, 1]\) there is exactly one point \(q \in B\) such that \(p-q\) is a rational number. Then this subset does not have a defined probability so it is “not measurable”.</li> <li>Even for nonmeasurable sets \(B\), we might be able to “approximate” a measure for \(B\) by taking the minimum/ maximum of measurable sets \(\mu (C)\) for measurable sets \(C\) where \(B \subset C\) / \(C \subset B\).</li> <li>We can build up “atoms” of positive probability in more interesting experiments. One such case for \(\Omega = [0, 1]\) would be that there is a 50% chance of observing 0, and probability (b-a)/2 of landing in [a,b] if \(a \neq 0\).</li> <li>In the next blog post, we’ll consider how for functions \(f : \Omega \rightarrow \Lambda\), we might be able to compare the probabilities in \(\Omega\) to the probabilities in \(f(\Omega) \subset \Lambda\).</li> </ol> <p>Exercises:</p> <ol> <li>For any measurable set \(B \subset \Omega\) and probability measure \(\mathbb{P}\), show that \(\mathbb{P}(B^c) = 1 - \mathbb{P}(B)\) so that the probability of landing outside of \(B\) is 1- probability of landing in B.</li> <li>For any measurable sets \(A, B \subset \Omega\) such that \(A \subset B\), show that \(\mathbb{P}(A) \leq \mathbb{P}(B)\).</li> </ol>]]></content><author><name></name></author><category term="Probability"/><summary type="html"><![CDATA[Probability Measures]]></summary></entry></feed>